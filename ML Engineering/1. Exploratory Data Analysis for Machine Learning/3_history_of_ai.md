# Early Excitement (1950s)

* **1950**: Alan Turing → *Turing Test*

  * Can a computer imitate a human so well that a judge can’t tell the difference?
* **1956**: Dartmouth Conference → term **Artificial Intelligence** coined; AI accepted as a research field.
* **1957**: Frank Rosenblatt → *Perceptron* algorithm (precursor to neural networks).
* **1959**: Arthur Samuel → checkers-playing program, popularized the term **machine learning**.

✨ Key point: Birth of **AI, ML, and early neural network ideas**.

---

## 2. First AI Winter (1960s–1970s)

* **Cause**: Hype around machine translation (esp. Russian ↔ English) failed.

  * **1966**: US Govt. report concluded little ROI from MT research.
* **1969**: Marvin Minsky showed major **limitations of perceptrons**.
* **1973**: Lighthill Report (UK) → highlighted lack of real progress → **funding cuts**.

❄️ **Impact**: Research slowed; funding collapsed.

---

## 3. Second Boom: Expert Systems & Neural Nets (1980s)

* **Expert systems**:

  * Rule-based algorithms mimicking human experts.
  * First **large-scale business adoption of AI**.
  * Ran on powerful mainframes, often coded in **LISP**.
* **Neural network revival**:

  * Geoffrey Hinton & others introduced **Backpropagation algorithm**.
  * Enabled **multi-layer networks** to update weights effectively.

✨ Key point: Business adoption + theoretical neural net breakthroughs.

---

## 4. Second AI Winter (Late 1980s–1990s)

* **Problems with expert systems**:

  * Couldn’t learn from new data.
  * Fragile → bad results with unusual inputs.
* **Problems with neural nets**:

  * Couldn’t scale to **large datasets/networks** at the time.
  * Backpropagation too slow, limited computing power.
* Business focus shifted → expert systems integrated into standard PC software → funding for mainframes/AI research declined.

❄️ **Impact**: Another crash in excitement & funding.

---

## 5. Path to Modern AI (Late 1990s–2000s, leading to today)

* Machine Learning (ML) found **practical success** in real tasks:

  * Speech recognition.
  * Google search ranking.
  * Data-driven applications.
* Advances in **data availability + computing power (GPUs + cloud)** → unlocked **deep learning**.
* Deep Learning models began outperforming traditional ML in **image classification, machine translation, and big data tasks**.

✨ Key point: Foundation of the **current AI boom**.

---

## 🔑 Takeaways

* AI has gone through **cycles of hype & disappointment** ("AI Winters").
* Progress depended heavily on:

  1. **Algorithms** (perceptron → backpropagation → deep nets).
  2. **Computing power**.
  3. **Data availability**.
* Today’s AI boom is different → **deep learning is delivering on promises** where past approaches fell short.