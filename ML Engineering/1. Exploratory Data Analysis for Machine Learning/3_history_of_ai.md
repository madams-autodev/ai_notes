# Early Excitement (1950s)

* **1950**: Alan Turing â†’ *Turing Test*

  * Can a computer imitate a human so well that a judge canâ€™t tell the difference?
* **1956**: Dartmouth Conference â†’ term **Artificial Intelligence** coined; AI accepted as a research field.
* **1957**: Frank Rosenblatt â†’ *Perceptron* algorithm (precursor to neural networks).
* **1959**: Arthur Samuel â†’ checkers-playing program, popularized the term **machine learning**.

âœ¨ Key point: Birth of **AI, ML, and early neural network ideas**.

---

## 2. First AI Winter (1960sâ€“1970s)

* **Cause**: Hype around machine translation (esp. Russian â†” English) failed.

  * **1966**: US Govt. report concluded little ROI from MT research.
* **1969**: Marvin Minsky showed major **limitations of perceptrons**.
* **1973**: Lighthill Report (UK) â†’ highlighted lack of real progress â†’ **funding cuts**.

â„ï¸ **Impact**: Research slowed; funding collapsed.

---

## 3. Second Boom: Expert Systems & Neural Nets (1980s)

* **Expert systems**:

  * Rule-based algorithms mimicking human experts.
  * First **large-scale business adoption of AI**.
  * Ran on powerful mainframes, often coded in **LISP**.
* **Neural network revival**:

  * Geoffrey Hinton & others introduced **Backpropagation algorithm**.
  * Enabled **multi-layer networks** to update weights effectively.

âœ¨ Key point: Business adoption + theoretical neural net breakthroughs.

---

## 4. Second AI Winter (Late 1980sâ€“1990s)

* **Problems with expert systems**:

  * Couldnâ€™t learn from new data.
  * Fragile â†’ bad results with unusual inputs.
* **Problems with neural nets**:

  * Couldnâ€™t scale to **large datasets/networks** at the time.
  * Backpropagation too slow, limited computing power.
* Business focus shifted â†’ expert systems integrated into standard PC software â†’ funding for mainframes/AI research declined.

â„ï¸ **Impact**: Another crash in excitement & funding.

---

## 5. Path to Modern AI (Late 1990sâ€“2000s, leading to today)

* Machine Learning (ML) found **practical success** in real tasks:

  * Speech recognition.
  * Google search ranking.
  * Data-driven applications.
* Advances in **data availability + computing power (GPUs + cloud)** â†’ unlocked **deep learning**.
* Deep Learning models began outperforming traditional ML in **image classification, machine translation, and big data tasks**.

âœ¨ Key point: Foundation of the **current AI boom**.

---

## ğŸ”‘ Takeaways

* AI has gone through **cycles of hype & disappointment** ("AI Winters").
* Progress depended heavily on:

  1. **Algorithms** (perceptron â†’ backpropagation â†’ deep nets).
  2. **Computing power**.
  3. **Data availability**.
* Todayâ€™s AI boom is different â†’ **deep learning is delivering on promises** where past approaches fell short.