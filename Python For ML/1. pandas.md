*Pandas* is a Python library that makes it easy to work with tabular data (data with rows and columns, like spreadsheets or SQL tables).

* Think of it as a supercharged Excel in Python!
* The most important concept in Pandas is the **DataFrame**

# DataFrame
* A DataFrame is like a table:
* Rows are like records in a database.
* Columns are features or attributes.
* Each column has a name (header).
* Each row has an index number (on the left).


*Data Structures:* Pandas offers two primary data structures - DataFrame and Series.

A DataFrame is a two-dimensional, size-mutable, and potentially heterogeneous tabular data structure with labeled axes (rows and columns).
A Series is a one-dimensional labeled array, essentially a single column or row of data.


Data Import and Export: Pandas makes it easy to read data from various sources, including CSV files, Excel spreadsheets, SQL databases, and more. It can also export data to these formats, enabling seamless data exchange.

Data Merging and Joining: You can combine multiple DataFrames using methods like merge and join, similar to SQL operations, to create more complex datasets from different sources.

Efficient Indexing: Pandas provides efficient indexing and selection methods, allowing you to access specific rows and columns of data quickly.

Custom Data Structures: You can create custom data structures and manipulate data in ways that suit your specific needs, extending Pandas' capabilities.

<!-- importing Pandas -->
import pandas as pd

<!-- Data Loading -->
# Read the CSV file into a DataFrame
df = pd.read_csv('your_file.csv')

<!-- Series -->

# Create a Series from a list
data = [10, 20, 30, 40, 50]
s = pd.Series(data)
print(s)

<!-- Accessing Elements in a Series -->

<!-- Accessing by label -->
print(s[2])     # Access the element with label 2

<!-- Accessing by position -->
print(s.iloc[3]) # Access the element at position 3

<!-- Accessing multiple elements -->
print(s[1:4])   # Access a range of elements by label

<!-- Series Attributes and Methods -->
values: Returns the Series data as a NumPy array.
index: Returns the index (labels) of the Series.
shape: Returns a tuple representing the dimensions of the Series.
size: Returns the number of elements in the Series.
mean(), sum(), min(), max(): Calculate summary statistics of the data.
unique(), nunique(): Get unique values or the number of unique values.
sort_values(), sort_index(): Sort the Series by values or index labels.
isnull(), notnull(): Check for missing (NaN) or non-missing values.
apply(): Apply a custom function to each element of the Series.



<!-- Creating DataFrames from Dictionaries -->
DataFrames can be created from dictionaries, with keys as column labels and values as lists representing rows.

# Creating a DataFrame from a dictionary
data = {'Name': ['Alice', 'Bob', 'Charlie', 'David'],
        'Age': [25, 30, 35, 28],
        'City': ['New York', 'San Francisco', 'Los Angeles', 'Chicago']}
df = pd.DataFrame(data)
print(df)

<!-- Column Selection -->
print(df['Name'])  # Access the 'Name' column

<!-- Accessing Rows -->
You can access rows by their index using .iloc[] or by label using .loc[].

print(df.iloc[2])   # Access the third row by position
print(df.loc[1])    # Access the second row by label


<!-- Slicing -->
You can slice DataFrames to select specific rows and columns.

print(df[['Name', 'Age']])  # Select specific columns
print(df[1:3])             # Select specific rows


<!-- Finding Unique Elements -->
Use the unique method to determine the unique elements in a column of a DataFrame.

unique_dates = df['Age'].unique()


<!-- Conditional Filtering -->
You can filter data in a DataFrame based on conditions using inequality operators.
For instance, you can filter albums released after a certain year.

high_above_102 = df[df['Age'] > 25]


<!-- Saving DataFrames -->
df.to_csv('trading_data.csv', index=False)

<!-- DataFrame Attributes and Methods -->

shape: Returns the dimensions (number of rows and columns) of the DataFrame.
info(): Provides a summary of the DataFrame, including data types and non-null counts.
describe(): Generates summary statistics for numerical columns.
head(), tail(): Displays the first or last n rows of the DataFrame.
mean(), sum(), min(), max(): Calculate summary statistics for columns.
sort_values(): Sort the DataFrame by one or more columns.
groupby(): Group data based on specific columns for aggregation.
fillna(), drop(), rename(): Handle missing values, drop columns, or rename columns.
apply(): Apply a function to each element, row, or column of the DataFrame.



<!-- Load Data -->
df = pd.read_csv('data.csv')         # From CSV
df = pd.read_excel('data.xlsx')      # From Excel
df = pd.read_json('data.json')       # From JSON
df = pd.read_sql(query, connection)  # From SQL


<!-- Save Data -->
df.to_csv('out.csv', index=False)
df.to_excel('out.xlsx')


<!-- Data Exploration -->
df.head()         # First 5 rows
df.tail(3)        # Last 3 rows
df.shape          # Rows, columns
df.columns        # Column names
df.info()         # Data types, nulls
df.describe()     # Summary stats
df.dtypes         # Data types


<!-- Data Cleaning -->
df.isnull().sum()             # Check nulls
df.dropna()                   # Drop null rows
df.fillna(0)                  # Fill nulls with 0
df['col'] = df['col'].fillna(df['col'].mean())  # Fill with mean
df.duplicated().sum()         # Check duplicates
df.drop_duplicates()          # Drop duplicate rows


<!-- Data Manipulation -->

<!-- Select Data -->
df['col']              # Single column
df[['col1', 'col2']]   # Multiple columns
df.iloc[0]             # First row by position
df.loc[0]              # First row by index

<!-- Filter Rows -->
df[df['sales'] > 1000]
df[(df['region'] == 'West') & (df['sales'] > 500)]

<!-- Create / Modify Columns -->
df['profit'] = df['revenue'] - df['cost']
df['date'] = pd.to_datetime(df['date'])

<!-- Rename or Drop -->
df.rename(columns={'old': 'new'}, inplace=True)
df.drop('column', axis=1, inplace=True)


<!-- Grouping & Aggregation -->
df.groupby('region')['sales'].sum()
df.groupby(['region', 'product'])['sales'].mean()
df['category'].value_counts()


<!-- Merging & Joining -->
pd.merge(df1, df2, on='customer_id', how='inner')
df1.join(df2, on='id', how='left')


<!-- Sorting & Ranking -->
df.sort_values('sales', ascending=False)
df['rank'] = df['score'].rank(ascending=False)

<!-- Pivot Tables & Crosstabs -->
df.pivot_table(index='region', columns='product', values='sales', aggfunc='sum')
pd.crosstab(df['gender'], df['purchased'])


<!-- Time Series -->
df['date'] = pd.to_datetime(df['date'])
df.set_index('date', inplace=True)
df.resample('M').sum()         # Monthly aggregation


<!-- Change Column Data Types -->
df['column_name'] = df['column_name'].astype(new_type)
df['age'] = df['age'].astype(int)
df['price'] = df['price'].astype(float)
df['gender'] = df['gender'].astype('category')
df['join_date'] = pd.to_datetime(df['join_date'])


<!-- Convert Multiple Columns -->
df = df.astype({
    'age': 'int',
    'income': 'float',
    'gender': 'category'
})
