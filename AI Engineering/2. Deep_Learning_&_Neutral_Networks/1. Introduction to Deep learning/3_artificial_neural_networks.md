# Artificial Neural Networks (ANNs)

## 1. ğŸ”‘ What is an Artificial Neuron?

* An **artificial neuron** = also called a **perceptron**.
* Inspired by **biological neurons**.
* Works by:

  1. Taking **inputs** (`x1, x2, ...`).
  2. Multiplying each input by a **weight** (`w1, w2, ...`).
  3. Adding a **bias (b)**.
  4. Passing the result through an **activation function** (e.g., sigmoid).

ğŸ‘‰ Formula:

```
z = w1*x1 + w2*x2 + ... + b  
a = activation(z)
```

* `z` = weighted sum + bias
* `a` = neuronâ€™s output

---

## 2. ğŸ—ï¸ Layers in a Neural Network

* **Input Layer** ğŸ¯ â†’ first layer, takes in raw data (numbers, images, text).
* **Hidden Layers** ğŸ§© â†’ middle layers where learning happens. Can be **1 or many**.
* **Output Layer** ğŸ“Š â†’ gives the final prediction (classification, number, text, etc.).

---

## 3. âš¡ Forward Propagation (How Data Flows)

* Forward propagation = **data moves from input â†’ hidden layers â†’ output**.
* At each neuron:

  1. Compute **weighted sum + bias**.
  2. Apply **activation function**.
  3. Pass output to the next layer.

---

## 4. ğŸ›ï¸ Activation Functions

Why do we need them?

* Without them â†’ network is just **linear regression**.
* With them â†’ network can learn **non-linear, complex tasks** (like image recognition, translation).

Popular one:

* **Sigmoid function**

  * If `z` â†’ large positive â†’ output close to **1**.
  * If `z` â†’ large negative â†’ output close to **0**.

ğŸ‘‰ Decides whether a neuron should "fire" (activate) or not.

---

## 5. ğŸ§® Example: Single Neuron

* Input: `x1 = 0.1`
* Weight: `w1 = 0.15`
* Bias: `b1 = 0.4`

Step 1: Compute `z`

```
z = w1*x1 + b1  
z = (0.15 * 0.1) + 0.4  
z = 0.415
```

Step 2: Apply sigmoid

```
a = sigmoid(z) â‰ˆ 0.6023
```

âœ… Output = **0.6023**

---

## 6. ğŸ”— Example: 2 Neurons (Chained)

* Neuron 1 output (`a1`) â†’ becomes input for Neuron 2.
* Neuron 2 computes:

```
z2 = w2*a1 + b2  
a2 = sigmoid(z2) â‰ˆ 0.7153
```

ğŸ‘‰ Final prediction = **0.7153**

---

## 7. ğŸ“Œ Key Takeaways

* ANN = many **perceptrons** stacked in **layers**.
* **Input â†’ Hidden â†’ Output**.
* **Forward propagation**: input flows forward through the network, producing an output.
* **Activation functions** make ANNs powerful by allowing **non-linear transformations**.
* Given **weights and biases**, you can compute the **output for any input**.

---

âœ… **Quick Pro Explanation for Beginners:**
Think of a neural network like a **factory**:

* Input layer = raw materials ğŸšš
* Hidden layers = machines that refine & transform ğŸ­
* Output layer = final product ğŸ“¦
* Activation functions = decision switches ğŸ”˜ that let the machines make **complex transformations**, not just simple ones.

---

ğŸ‘‰ Do you want me to also create a **colorful side-by-side Markdown table** comparing **Forward Propagation vs Backpropagation**, so youâ€™ll be ready when the course moves to the next topic?
